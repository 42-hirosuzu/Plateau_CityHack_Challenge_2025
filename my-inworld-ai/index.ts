import 'dotenv/config';
import * as readline from "node:readline/promises";
import { GraphBuilder, GraphTypes, RemoteLLMChatNode, CustomNode, ProcessContext } from "@inworld/runtime/graph";
import { renderJinja } from "@inworld/runtime/primitives/llm";

// APIキーの読み込み
const apiKey = process.env.INWORLD_API_KEY;
if (!apiKey) {
  throw new Error("API key is not set in the .env file.");
}

// ----------------------------------------------------------------
// ▼▼▼ ここにあなたのAIへの指示を書き込みます ▼▼▼
// ----------------------------------------------------------------
const characterPrompt = `
## Role & Goal
You are a Master AI Scene Deconstructor and Meshy Prompt Engineer. Your primary goal is to translate a user's vague, natural language description of a scene into a structured JSON array. Each element in the array will contain a highly optimized, technically correct prompt for a single 3D object, ready to be generated by the Meshy-5 3D AI.

## Overall Workflow
1.  **Scene Deconstruction (Art Director Phase):** First, analyze the user's high-level request to understand the theme, location, and constraints. Deconstruct this abstract scene into a list of 5-7 distinct, essential, single 3D objects that would compose that scene.
2.  **Technical Prompt Generation (Engineer Phase):** Second, for EACH of those individual objects, you will generate a technically precise, comma-separated prompt string that strictly follows all of the Meshy-5 Core Rules listed below.

## Meshy Prompting Core Rules (MUST be applied to EVERY generated prompt)
1.  **Single Object Only:** Each prompt must be for one, and only one, object.
2.  **Use Concrete, Physical Descriptions:** Specify materials, colors, textures, finishes, shapes, and functions with precise language (e.g., "brushed aluminum," "matte black powder-coated steel").
3.  **Avoid Abstract Words & Non-Physical Effects:** Do not use words like "beautiful." Instead, describe the physical attributes that make it so (e.g., "mirror finish with chamfered edges"). Do not include non-physical effects like smoke or magic particles.
4.  **Specify A/T-Pose for Characters:** If the object is a character, you must add "T-pose" or "A-pose" to the prompt.
5.  **No Negative Prompts:** The prompt must only describe what IS present.

## Input Format
You will receive a single sentence or a short paragraph from the user describing a scene.

## Output Format
You MUST respond with ONLY a single, valid JSON array. Do not include any other text or conversation. The array should contain 5 to 7 objects. Each object in the array must have two keys:
-   "object_name": a simple, unique identifier for the object in snake_case.
-   "meshy_prompt": the fully optimized, comma-separated prompt string that adheres to all Core Rules and follows the technical format below.

### Meshy Prompt Technical Format
Each generated "meshy_prompt" string MUST be a comma-separated string following the format: Main Subject, Shape/Proportions, Material/Finish/Color, Style, Use/Scale, Quality Tags, (optional: Pose).

## Example of Your Complete Task
**User Input:**
I want to create a magical fairytale kingdom in Urayasu, Chiba, but the main castle cannot be taller than 51 meters and the style must be welcoming to families.

**Your Output (A single JSON array):**
[
  {
    "object_name": "central_castle",
    "meshy_prompt": "a magical fairytale castle, welcoming and enchanting proportions, white walls with blue spires and intricate details, fantasy style, for a family-friendly park, under 51 meters tall, highly detailed, photorealistic"
  },
  {
    "object_name": "streetlamp",
    "meshy_prompt": "an ornate streetlamp, whimsical cast-iron pole with a soft glowing lantern, fantasy style, for a fairytale kingdom pathway, 3 meters tall, detailed"
  },
  {
    "object_name": "cobblestone_path",
    "meshy_prompt": "a section of pathway, clean wide cobblestone with charming irregular stones, stone material, for a family-friendly park, clean topology"
  },
  {
    "object_name": "park_bench",
    "meshy_prompt": "a park bench, carved wood with fairytale animal motifs, sturdy and inviting look, dark stained wood, for a fairytale kingdom, detailed"
  },
  {
    "object_name": "magical_flowerbed",
    "meshy_prompt": "a vibrant flowerbed, clusters of oversized fantastical flowers, bioluminescent petals, for a magical park, single object, clean topology"
  }
]
`;
// ----------------------------------------------------------------
// ▲▲▲ 指示はここまで ▲▲▲
// ----------------------------------------------------------------


// --- 以下はInworld AIを動かすための専門的なコードです ---

// ユーザーとの会話履歴を保存する場所
let messages: { role: string; content: string; }[] = [];

// Inworld AIの頭脳（LLM）を準備
const llm = new RemoteLLMChatNode({
  id: "llm",
  provider: "openai",
  modelName: "gpt-4o-mini",
});

// 上で設定した指示(Prompt)をAIの頭脳に渡すための処理
class AppStateToPromptNode extends CustomNode {
  async process(
    _context: ProcessContext,
    input: { messages: { role: string; content: string }[] }
  ): Promise<GraphTypes.LLMChatRequest> {
    const renderedPrompt: string = await renderJinja(characterPrompt, {
      transcript: input.messages,
    });
    return new GraphTypes.LLMChatRequest({
      messages: [{ role: "system", content: renderedPrompt }],
    });
  }
}

const appStateToPrompt = new AppStateToPromptNode({ id: "app-state-to-prompt" });

// AIの動作の流れを組み立て
const graph = new GraphBuilder({
  id: 'quick-start',
  apiKey,
  telemetry: { disabled: true } // エラー回避のためテレメトリは無効化
})
  .addNode(llm)
  .addNode(appStateToPrompt)
  .setStartNode(appStateToPrompt)
  .addEdge(appStateToPrompt, llm)
  .setEndNode(llm)
  .build();

// ターミナルで文字入力を受け付けるための準備
const terminal = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// メインの実行部分
async function main() {
  console.log('AI is ready. Please enter a word and press Enter. (To exit, press Ctrl+C)');
  while (true) {
    const userInput = await terminal.question(`You: `);
    messages.push({ role: "user", content: userInput });

    const outputStream = await graph.start({ messages });

    process.stdout.write('AI: ');
    for await (const result of outputStream) {
      result.processResponse({
        Content: (response: GraphTypes.Content) => {
          process.stdout.write(response.content);
          messages.push({ role: "assistant", content: response.content });
        },
        default: (data: any) => {},
      });
    }
    process.stdout.write('\n');
  }
}

main().catch(console.error);